{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=pd.read_csv('cora.content.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "el=pd.read_csv('cora.cites.txt',sep='\\t',header=None)\n",
    "el.columns=['source','target']\n",
    "G=nx.from_pandas_edgelist(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "node=list(content[0])\n",
    "wordvec=[]\n",
    "for i in range(len(content)):\n",
    "    wordvec.append(list(content.loc[i,1:1433]))\n",
    "field=list(content[1434])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,vertex in enumerate(node):\n",
    "    # G.nodes[vertex]['content']=wordvec[i]\n",
    "    G.nodes[vertex]['field']=field[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_mat(n,m):\n",
    "    np.random.seed(1000)\n",
    "    rdmat=np.zeros((n,m))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            rdmat[i,j]=np.random.rand()+1\n",
    "    rdmat=rdmat/np.sum(rdmat,axis=1)[:,np.newaxis]\n",
    "    return rdmat\n",
    "\n",
    "def loged_division_scale(bs,maxnum,minnum):\n",
    "    adj=(maxnum+minnum)/2\n",
    "    b=np.array(bs)-adj\n",
    "    return np.exp(b)/sum(np.exp(b))\n",
    "\n",
    "def loged_division(bs):\n",
    "    maxnum=max(bs)\n",
    "    a=np.zeros(len(bs))\n",
    "    ind=bs>=(maxnum-1000)\n",
    "    a[ind]=loged_division_scale(bs[ind],maxnum=maxnum,minnum=min(bs[ind]))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "\n",
    "u, v = g.edges()\n",
    "eids = np.arange(g.number_of_edges())\n",
    "eids = np.random.permutation(eids)  # 将顺序打乱\n",
    "\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))  \n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes()) \n",
    "neg_u, neg_v = np.where(adj_neg != 0)  \n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]\n",
    "\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats,aggregator_type='mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats,aggregator_type='mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.6930727362632751\n",
      "In epoch 5, loss: 0.6797953248023987\n",
      "In epoch 10, loss: 0.6405137181282043\n",
      "In epoch 15, loss: 0.5821075439453125\n",
      "In epoch 20, loss: 0.5371377468109131\n",
      "In epoch 25, loss: 0.5234941840171814\n",
      "In epoch 30, loss: 0.5015429854393005\n",
      "In epoch 35, loss: 0.4823758900165558\n",
      "In epoch 40, loss: 0.465501070022583\n",
      "In epoch 45, loss: 0.448535680770874\n",
      "In epoch 50, loss: 0.43461722135543823\n",
      "In epoch 55, loss: 0.42184972763061523\n",
      "In epoch 60, loss: 0.408948689699173\n",
      "In epoch 65, loss: 0.3967340290546417\n",
      "In epoch 70, loss: 0.38518255949020386\n",
      "In epoch 75, loss: 0.373823344707489\n",
      "In epoch 80, loss: 0.36286282539367676\n",
      "In epoch 85, loss: 0.3520471751689911\n",
      "In epoch 90, loss: 0.3414112329483032\n",
      "In epoch 95, loss: 0.33100834488868713\n",
      "In epoch 100, loss: 0.32093438506126404\n",
      "In epoch 105, loss: 0.31095990538597107\n",
      "In epoch 110, loss: 0.3012780547142029\n",
      "In epoch 115, loss: 0.29179197549819946\n",
      "In epoch 120, loss: 0.2825547158718109\n",
      "In epoch 125, loss: 0.2735680043697357\n",
      "In epoch 130, loss: 0.26482564210891724\n",
      "In epoch 135, loss: 0.25638729333877563\n",
      "In epoch 140, loss: 0.24800719320774078\n",
      "In epoch 145, loss: 0.24017322063446045\n",
      "In epoch 150, loss: 0.2321750372648239\n",
      "In epoch 155, loss: 0.22448043525218964\n",
      "In epoch 160, loss: 0.21689531207084656\n",
      "In epoch 165, loss: 0.20932598412036896\n",
      "In epoch 170, loss: 0.20179195702075958\n",
      "In epoch 175, loss: 0.19454438984394073\n",
      "In epoch 180, loss: 0.1866036355495453\n",
      "In epoch 185, loss: 0.17890843749046326\n",
      "In epoch 190, loss: 0.17146630585193634\n",
      "In epoch 195, loss: 0.16384698450565338\n",
      "In epoch 200, loss: 0.1564532071352005\n",
      "In epoch 205, loss: 0.14934585988521576\n",
      "In epoch 210, loss: 0.14384004473686218\n",
      "In epoch 215, loss: 0.136802077293396\n",
      "In epoch 220, loss: 0.1301441639661789\n",
      "In epoch 225, loss: 0.12394405156373978\n",
      "In epoch 230, loss: 0.11810161918401718\n",
      "In epoch 235, loss: 0.11246753484010696\n",
      "In epoch 240, loss: 0.10701224207878113\n",
      "In epoch 245, loss: 0.10170935094356537\n",
      "In epoch 250, loss: 0.09659847617149353\n",
      "In epoch 255, loss: 0.09163179993629456\n",
      "In epoch 260, loss: 0.08687593042850494\n",
      "In epoch 265, loss: 0.08235269039869308\n",
      "In epoch 270, loss: 0.07783999294042587\n",
      "In epoch 275, loss: 0.07353349030017853\n",
      "In epoch 280, loss: 0.0695498064160347\n",
      "In epoch 285, loss: 0.06599187105894089\n",
      "In epoch 290, loss: 0.0619446337223053\n",
      "In epoch 295, loss: 0.05823477730154991\n",
      "In epoch 300, loss: 0.05495135113596916\n",
      "In epoch 305, loss: 0.05167963728308678\n",
      "In epoch 310, loss: 0.04850205406546593\n",
      "In epoch 315, loss: 0.04556360840797424\n",
      "In epoch 320, loss: 0.04275418817996979\n",
      "In epoch 325, loss: 0.040049098432064056\n",
      "In epoch 330, loss: 0.03750889003276825\n",
      "In epoch 335, loss: 0.03510013967752457\n",
      "In epoch 340, loss: 0.032787710428237915\n",
      "In epoch 345, loss: 0.03062906116247177\n",
      "In epoch 350, loss: 0.028590422123670578\n",
      "In epoch 355, loss: 0.026666760444641113\n",
      "In epoch 360, loss: 0.0248566847294569\n",
      "In epoch 365, loss: 0.0231565423309803\n",
      "In epoch 370, loss: 0.0215603020042181\n",
      "In epoch 375, loss: 0.020063208416104317\n",
      "In epoch 380, loss: 0.018660878762602806\n",
      "In epoch 385, loss: 0.017349369823932648\n",
      "In epoch 390, loss: 0.016126325353980064\n",
      "In epoch 395, loss: 0.014985025860369205\n",
      "In epoch 400, loss: 0.01392313838005066\n",
      "In epoch 405, loss: 0.012935982085764408\n",
      "In epoch 410, loss: 0.012017494067549706\n",
      "In epoch 415, loss: 0.011164803057909012\n",
      "In epoch 420, loss: 0.010373294353485107\n",
      "In epoch 425, loss: 0.009641065262258053\n",
      "In epoch 430, loss: 0.008964663371443748\n",
      "In epoch 435, loss: 0.008343128487467766\n",
      "In epoch 440, loss: 0.007770971395075321\n",
      "In epoch 445, loss: 0.007244069594889879\n",
      "In epoch 450, loss: 0.006757060997188091\n",
      "In epoch 455, loss: 0.006306042894721031\n",
      "In epoch 460, loss: 0.005887039005756378\n",
      "In epoch 465, loss: 0.005498203914612532\n",
      "In epoch 470, loss: 0.005137575790286064\n",
      "In epoch 475, loss: 0.0048044826835393906\n",
      "In epoch 480, loss: 0.004497809335589409\n",
      "In epoch 485, loss: 0.004215329419821501\n",
      "In epoch 490, loss: 0.003956446424126625\n",
      "In epoch 495, loss: 0.00371725857257843\n",
      "AUC 0.7911924709687563\n"
     ]
    }
   ],
   "source": [
    "model = GraphSAGE(g.ndata['feat'].shape[1], 7)\n",
    "pred = DotPredictor()\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)\n",
    "\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "all_logits = []\n",
    "for e in range(500):\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print('In epoch {}, loss: {}'.format(e, loss))\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.2234], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pred_edge = dgl.graph((np.array([1]), np.array([4])), num_nodes=g.number_of_nodes())\n",
    "pred(to_pred_edge,h)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ae58900cfbb8c43ab3495913814b7cf26024f51651a94ce8bf64d6111688e8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
